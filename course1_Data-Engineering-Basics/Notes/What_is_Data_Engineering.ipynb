{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN+OKZea0Gw5NfnUTKSDQhx"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# What is Data Engineering?\n",
        "Data engineering involves **designing, building, and maintaining** **data infrastructures and platforms**. These infrastructures include databases, big data repositories, and data pipelines for transforming and moving data between systems. A data engineer develops and optimizes these data systems to ensure data is available for analysis.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PhAJUdtBsR3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center> \"The constant increase in data processing speeds and bandwidth, the nonstop invention of new tools for creating, sharing, and consuming data, and the steady addition of new data creators and consumers ensure that data growth continues unabated.\" — Forbes, 2020 </center>"
      ],
      "metadata": {
        "id": "DvtH1M2MaUIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Role of a Data Engineer\n",
        "Data engineers act as the \"plumbers of data,\" ensuring seamless data flow within an organization. Their work enables analysts and scientists to use data effectively by choosing the right databases, storage systems, and cloud architectures."
      ],
      "metadata": {
        "id": "1OnTK8nKaDb3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Key Responsibilities of a Data Engineer\n",
        "The overarching responsibility of a data engineer is to provide analytics-ready data to data consumers. Data is analytics-ready when it is:\n",
        "\n",
        "* **Accuracy** – Ensuring data correctness.\n",
        "* **Efficiency** – Accessing needed data quickly.\n",
        "* **Compliant with regulations**\n",
        "\n",
        "#### At a broad level, data engineers:\n",
        "\n",
        "✔ **Extract** data from various sources (databases, APIs, logs, IoT devices, etc.)\n",
        "\n",
        "✔ **Integrate** data from disparate systems into a unified format\n",
        "\n",
        "✔ **Organize** & **Store** data in repositories like data warehouses, data lakes, or relational/non-relational databases\n",
        "\n",
        "✔ **Build & Maintain Data Pipeline** to ensure data flows smoothly for analysis\n",
        "\n",
        "Essentially, Data Engineers **create the infrastructure** that allows Data Analysts and Data Scientists to **access, analyze, and derive insights from data.**"
      ],
      "metadata": {
        "id": "PyQs4_IOeXPf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Key Skills for Data Engineers"
      ],
      "metadata": {
        "id": "iZXHtZIWfNP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Technical Skills\n",
        "\n",
        "1. **Operating Systems**:\n",
        "  - UNIX\n",
        "  - Linux\n",
        "  - Windows\n",
        "  - system administration tools\n",
        "\n",
        "2. **Infrastructure Components**:\n",
        "  - Virtual machines\n",
        "  - networking\n",
        "  - application services\n",
        "  - cloud platforms (AWS, Google Cloud, IBM, Microsoft Azure)\n",
        "\n",
        "3. **Databases and Data Warehouses**:\n",
        "  - RDBMS: IBM DB2, MySQL, Oracle Database, PostgreSQL\n",
        "  - NoSQL: Redis, MongoDB, Cassandra, Neo4J\n",
        "  - Data Warehouses: Oracle Exadata, IBM Db2 Warehouse on Cloud, Amazon Redshift\n",
        "\n",
        "4. **Data Pipelines**: Gather data from multiple sources, transform it into analytics-ready data, and make it available to data consumers.\n",
        "  - Apache Beam\n",
        "  - AirFlow\n",
        "  - DataFlow\n",
        "\n",
        "5. **ETL Tools**:\n",
        "  - IBM Infosphere\n",
        "  - AWS Glue\n",
        "  - Improvado\n",
        "\n",
        "6. **Programming Languages**:\n",
        "\n",
        "  - Query Languages: SQL, SQL-like NoSQL queries\n",
        "  - General Purpose: Python, R, Java\n",
        "  - Scripting: Unix/Linux Shell, PowerShell\n",
        "\n",
        "7. **Big Data Processing**: Essential for handling vast amounts of structured and unstructured data.\n",
        "  - Hadoop\n",
        "  - Hive\n",
        "  - Spark"
      ],
      "metadata": {
        "id": "V2DkoIbei6g7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Functional Skills\n",
        "\n",
        "- Converting business requirements into technical specifications.\n",
        "\n",
        "- Understanding the complete software development lifecycle.\n",
        "\n",
        "- Knowledge of business applications of data.\n",
        "\n",
        "- Awareness of risks in data management (quality, privacy, security, compliance)."
      ],
      "metadata": {
        "id": "rMsVsl5Oi-3t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Soft Skills\n",
        "\n",
        "- Collaboration with data analysts, scientists, and business users.\n",
        "\n",
        "- Strong interpersonal communication with both technical and non-technical stakeholders.\n",
        "\n",
        "- Ability to work in a team-oriented environment."
      ],
      "metadata": {
        "id": "ZJ7_jSOKjEjN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Roles Comparison\n",
        "**Data Engineer**: Develops and maintains data architectures, pipelines, and repositories, ensuring data availability, consistency, security, and recoverability.\n",
        "\n",
        "**Data Analyst**: Inspects, cleans, and analyzes data to derive insights.\n",
        "\n",
        "**Data Scientist**: Builds predictive models using machine learning and statistical analysis.\n",
        "\n",
        "**Business Analysts**: Use data insights to inform business decisions.\n",
        "\n",
        "**BI Analysts**: Focus on market forces and external business influences."
      ],
      "metadata": {
        "id": "N995_RYEj5AU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example Data Engineering Project\n",
        "\n",
        "Sarah Flinch, a Data Engineer at a multinational hair care company, worked on a project to track customer sentiment for a new shampoo launch.\n",
        "\n",
        "* The business team wanted real-time insights from social media and eCommerce platforms.\n",
        "\n",
        "* Data Scientists built a sentiment analysis dashboard prototype with dummy data.\n",
        "\n",
        "* Sarah’s team collected product-related tweets, posts, and reviews using APIs and web scraping.\n",
        "\n",
        "* She processed and stored the data in a database, which powered the dashboard.\n",
        "\n",
        "* To ensure real-time updates, Sarah implemented a data pipeline that automated data extraction, transformation, and loading (ETL).\n",
        "\n",
        "This system enabled business users to monitor brand perception instantly without manual intervention."
      ],
      "metadata": {
        "id": "lRDeD8dERjkR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Sources\n",
        "\n",
        "Data originates from **structured** and **unstructured** datasets such as:\n",
        "\n",
        "* Text, images, videos, clickstreams, user conversations, and social media.\n",
        "\n",
        "* IoT devices, real-time event streams, legacy databases, and third-party data providers."
      ],
      "metadata": {
        "id": "sb8Y2HQwabiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stages of Data Processing\n",
        "\n",
        "* **Data Acquisition**: Extracting and importing data from various sources while ensuring security and integrity.\n",
        "\n",
        "* **Data Preparation**: Organizing, cleaning, and optimizing data for accessibility and compliance.\n",
        "\n",
        "* **Data Storage**: Managing repositories with high availability, flexibility, and security.\n",
        "\n",
        "* **Data Access & Consumption**: Making data available through APIs, reports, dashboards, and analytical tools."
      ],
      "metadata": {
        "id": "MzpD9KNTbGFK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module 1 Practice Quiz (1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "89WXhUWKFywB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.) Which emerging technology has made it possible for every enterprise to have access to limitless storage and high-performance computing?\n",
        "\n",
        "<details>\n",
        "  <summary>ANSWER</summary>\n",
        "    \n",
        "    ↪ Cloud Computing\n",
        "\n",
        "Cloud technologies has made it possible for every enterprise, regardless of its size, to have access to limitless storage and high-performance computing at nominal costs.\n",
        "</details>"
      ],
      "metadata": {
        "id": "qxCpEGWuN0Km"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.) Which of the data roles is responsible for extracting, integrating, and organizing data into data repositories?\n",
        "\n",
        "<details>\n",
        "  <summary>ANSWER</summary>\n",
        "    \n",
        "    ↪ Data Engineers\n",
        "\n",
        "Data Engineers are responsible for extracting, integrating, and organizing data into data repositories.\n",
        "</details>"
      ],
      "metadata": {
        "id": "qEje5S3zGLG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.) The field of data engineering concerns itself with the mechanics for the flow and access of data. What captures the goal of data engineering?\n",
        "\n",
        "<details>\n",
        "  <summary>ANSWER</summary>\n",
        "    \n",
        "    ↪ Make quality data available for fact-finding and business decision-making\n",
        "\n",
        "  Data engineering is the process of collecting raw data and converting it into analytics-ready data by cleaning, transforming, and preparing data so that it is reliable.\n",
        "</details>"
      ],
      "metadata": {
        "id": "LDOi0f8QHcVt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module 1 Practice Quiz (2)"
      ],
      "metadata": {
        "id": "8qieYzJjlsnL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.) Which one of these skills is essential to the role of a Data Engineer?\n",
        "\n",
        "<details>\n",
        "  <summary>ANSWER</summary>\n",
        "    \n",
        "    ↪ To set up and manage the infrastructure required for the ingestion, processing, and storage of data.\n",
        "\n",
        "  Data Engineers are responsible for setting up and managing the infrastructure required for ingesting raw data, processing it, and storing it so that it is available for analytics.\n",
        "</details>"
      ],
      "metadata": {
        "id": "khn8QdT_mOx8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.) What, according to Sarah Flinch, needs to be tracked and analyzed in order to keep business updated on the overall sentiment of the consumers?\n",
        "\n",
        "<details>\n",
        "  <summary>ANSWER</summary>\n",
        "    \n",
        "    ↪ Social media posts, customer reviews and ratings on eCommerce platforms, and product reviews on blogging sites.\n",
        "\n",
        " How a product gets talked about on social media, eCommerce platforms, and blogging sites has an immediate impact on sales numbers and brand perception.\n",
        "</details>"
      ],
      "metadata": {
        "id": "sWuFGP8lmoDD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module 1 Graded Quiz"
      ],
      "metadata": {
        "id": "yywkTAJZnjKY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.) Data Engineers work within the data ecosystem to:\n",
        "\n",
        "    A. Analyze data for actionable insights\n",
        "\n",
        "    B. Analyze data for deriving insights\n",
        "\n",
        "    C. Provide business intelligence solutions by monitoring data on different business functions\n",
        "\n",
        "    D. Develop and maintain data architectures\n",
        "\n",
        "  <details>\n",
        "  <summary>ANSWER</summary>\n",
        "    \n",
        "    ↪ D. Develop and maintain data architectures.\n",
        "\n",
        " One of the responsibilities of a Data Engineer in a data ecosystem is to develop and maintain data architectures so that data is available for business operations and analysis.\n",
        "</details>"
      ],
      "metadata": {
        "id": "x3MXDZF2nn7c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.) The goal of data engineering is to make quality data available for fact-finding and decision-making. Which one of these statements captures the process of data engineering?\n",
        "\n",
        "    A. Processing data and making it available to users securely\n",
        "    \n",
        "    B. Collecting, processing, and making data available to users securely\n",
        "    \n",
        "    C. Collecting, processing, and storing data\n",
        "    \n",
        "    D. Collecting, processing, storing, and making data available to users securely\n",
        "\n",
        "  <details>\n",
        "  <summary>ANSWER</summary>\n",
        "    \n",
        "    ↪ D. Collecting, processing, storing, and making data available to users securely.\n",
        "\n",
        " Data engineering includes the collection of data from disparate sources, processing data so that it is usable, storing processed data, and making it available to users securely.\n",
        "</details>"
      ],
      "metadata": {
        "id": "cKHD3OKFogdt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.) Data extracted from disparate sources can be stored in:\n",
        "\n",
        "    A. Data Lakes only\n",
        "    \n",
        "    B. Databases only\n",
        "    \n",
        "    C. Data Warehouses only\n",
        "    \n",
        "    D. Databases, data warehouses, data lakes, or any other type of data repository\n",
        "\n",
        "  <details>\n",
        "  <summary>ANSWER</summary>\n",
        "    \n",
        "    ↪ D. Databases, data warehouses, data lakes, or any other type of data repository.\n",
        "\n",
        " Data extracted from multiple sources can be stored in any type of data repository, such as, databases, data warehouses, and data lakes.\n",
        "</details>"
      ],
      "metadata": {
        "id": "2hZ5Lj0QpPWL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.) From the provided list, select the three emerging technologies that are shaping today’s data ecosystem.\n",
        "\n",
        "    A. Big Data, Internet of Things, and Dashboarding\n",
        "    \n",
        "    B. Cloud Computing, Internet of Things, and Dashboarding\n",
        "    \n",
        "    C. Machine Language, Cloud Computing, and Internet of Things\n",
        "    \n",
        "    D. Cloud Computing, Machine Learning, and Big Data\n",
        "\n",
        "  <details>\n",
        "  <summary>ANSWER</summary>\n",
        "    \n",
        "    ↪ D. Cloud Computing, Machine Learning, and Big Data.\n",
        "\n",
        " Emerging technologies such as Cloud Computing, Machine Learning, and Big Data are shaping today’s data ecosystem and its possibilities.\n",
        "</details>"
      ],
      "metadata": {
        "id": "_N88R3JYqY-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.) Oracle Exadata, IBM Db2 Warehouse on Cloud, IBM Netezza Performance Server, and Amazon RedShift are some of the popular __________________ in use today.\n",
        "\n",
        "    A. Big Data Platforms\n",
        "    \n",
        "    B. ETL Tools\n",
        "    \n",
        "    C. NoSQL Databases\n",
        "    \n",
        "    D. Data Warehouses\n",
        "\n",
        "  <details>\n",
        "  <summary>ANSWER</summary>\n",
        "    \n",
        "    ↪ D. Data Warehouses.\n",
        "\n",
        " These are some of the popularly used data warehouses.\n",
        "</details>"
      ],
      "metadata": {
        "id": "HMhVpRkQrlfE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.) Data Engineers manage the infrastructure required for the ingestion, processing, and storage of data.\n",
        "\n",
        "    A. True\n",
        "    \n",
        "    B. False\n",
        "\n",
        "  <details>\n",
        "  <summary>ANSWER</summary>\n",
        "    \n",
        "    ↪ A. True.\n",
        "\n",
        " This is one of the primary responsibilities of a Data Engineer.\n",
        "</details>"
      ],
      "metadata": {
        "id": "5t6k5g_zsy0q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.) To ensure business stakeholders can see real-time data each time they log into the dashboard, Sarah decided to build _______________ to extract, transform, and load data on an ongoing basis.\n",
        "\n",
        "    A. A sentiment analysis algorithm\n",
        "    \n",
        "    B. APIs\n",
        "    \n",
        "    C. A Python program\n",
        "    \n",
        "    D. A Data Pipeline\n",
        "\n",
        "  <details>\n",
        "  <summary>ANSWER</summary>\n",
        "    \n",
        "    ↪ D. A Data Pipeline.\n",
        "\n",
        " Data pipelines cover the journey of data from source to destination systems which include extracting, transforming, and loading data.\n",
        "</details>"
      ],
      "metadata": {
        "id": "I4H4tSAHvH9t"
      }
    }
  ]
}